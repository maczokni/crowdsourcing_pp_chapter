---
title: "Crowdsourcing public perceptions of space and safety"
abstract: "Insert abstract here
  \\par
  \\textbf{Keywords:} Fear of crime, perceived safety, crime mapping, open data, GIS, Atlanta"
author: |
  | David Buil-Gil and Reka Solymosi
  | Department of Criminology, University of Manchester, UK
date: "24/04/2020"
output:
  pdf_document: default
  word_document: default
bibliography: refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
library(sf)
library(ineq)
library(lubridate)
library(tidyr)
library(dplyr)
```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

**Full reference:** Buil-Gil, D., & Solymosi, R. (2020). Crowdsourcing public perceptions of space and safety. In E. Groff & C. Haberman (Eds.), *The Study of crime and place: A methods handbook*. Temple University Press.

**Contact details:** David Buil-Gil. G18 Humanities Bridgeford Street Building, Cathie Marsh Institute for Social Research, University of Manchester. E-mail address: *david.builgil@manchester.ac.uk*

**ORCID IDs:** David Buil-Gil: 0000-0002-7549-6317. Reka Solymosi: 0000-0001-8689-1526.

# 1. Introduction 

Crowdsourcing refers to the practise of enlisting the knowledge, experience or skills of a large number of citizens (*the 'crowd'*) to achieve a common goal or cumulative result, usually via a platform powered by digital technologies, mobile phones, social media or a website [@howe2006]. Digital platforms allow recording large volumes of data in relatively little time at a very small cost, which explains why data generated through crowdsourcing is currently utilized for a variety of function ranging from academic research to policy making and emergency management [@brabham2008; @goodchild2007]. As an example, during the 2007-2009 wildfires in the Santa Barbara area, California, residents shared their real-time knowledge about the location of fires and emergency shelters via various online forums and websites, which proved to be an invaluable source of information for disaster response [@goodchild2010]. Similarly, crowdsourcing projects have been deployed to harness people's experiences with crime and their perceptions about space and safety [e.g., @solymosi2018; @williams2017]. In this chapter we review some published literature about the use of crowdsourcing for criminological research, discuss the main strenghts and limitations of data produced from crowdsourcing platforms, and present an step-by-step exemplar study in `R` software [@R2020] using crowdsourced perceptions of safety in Atlanta, Georgia.

In criminological research, crowdsourcing analysis has been primarily used to harness data about various forms of crime and antisocial behavior and to process information about citizens' perceptions and emotions about crime, thus allowing researchers to devise new explanations of crime and perceived safety. On one hand, open data recorded from social media and online forums enables detecting various forms of online crimes [e.g., hate speech towards minority groups; @miro2018], and even associate those forms of online hate speech with offline racially and religiously aggravated crimes [@williams2020]. Moreover, @williams2017 [p. 334] argue that "open-source communications, in particular from Twitter, have potential for measuring the breakdown of social and physical order at the borough level", which is also shown by @erete2016. Thus, some criminologists use large crowdsourced datasets to detect and explain criminal activity.

On the other hands, those researchers interested in the public perceptions about space and safety explore the use of volunteered crowdsourced information to explain the citizens' perceptions and emotions about crime. Criminologists have long known that public emotions about crime are not always explained by the prevalence and harms of crime, but instead fear of crime emotions are the result of individual predispositions to experience negative emotions about crime, which become fear of crime episodes under the presence of certain social and situational influences [@gabriel2003; @hale1996]. The public perceptions and emotions about crime have traditionally been analysed by using surveys and interview-type qualitative approaches [see @gabriel2003; @warr2000], but these methods are costly and may be limited to capture the time and context-specific emotional reactions of fear of crime as well as the citizens' behavioural responses to such emotions of fear (e.g., avoidance behaviors, acquiring alarm systems or weapons). As an alternartive, some researchers have endorsed the use crowdsourcing and app-based tool to record data about the places and times in which episodes of fear of crime are more frequent, in order to fully conceptualize and operationalize the fear of crime as a function of individuals and their immediate environment [@solymosi2018; @solymosi2020].

To mention only a few examples of crowdsourcing platforms deployed to record data about perceptions and emotions about crime, @hamilton2011 developed a mobile phone app to record public perceptions of crime on public transportation in Melbourne, Australia. Similarly, @solymosi2015 designed an app and asked participants to report their worry about crime, which allows authors to map the users' fear pf crime across the different areas of London, UK. @salesses2013 designed and recorded data from the Place Pluse platform, which asks participants to choose 'which place looks safer' between two images taken from Google Street View. Then @salesses2013 produced a map of perceived safety in New York, USA. @birendoim2016 developed a mobile app to record data about the perceptions of security of attendees at a music festival in Jerusalem, Israel. @gomez2016 designed a collaborative web-based tool that allowed the citizens of Bogota, Colombia, to report those areas in which they feel less safe. And @solymosi2017 analysed secondary data recorded by FixMyStreet, an online problem reporting website, to examine perceptions of neighborhood disorder in London, UK. These are only a few examples, but there are many others crowdsourcing platforms that have been designed and utilized to study the fear of crime [see @solymosi2020].

# 2. Strengths and weaknesses of crowdsourced data

Although crowdsourced data about public perceptions of space and safety have some key strengths over data recorded by traditional survey methods (e.g., precise spatial data, information about immediate environmental variables, reduced cost), their unique mode of production is also associated to certain limitations or weaknesses that, if uncontrolled, may affect the validity of such measures and the reliability of final results [@builgil2020; @elliott2017]. Amongst those limitations identified by researchers using crowdsourced data to study the fear of crime, the ones that are most commonly mentioned are related to the participation inequality arising from self-selection in crowdsourced samples, the difficulty to interpret results, and the under-representation of certain areas and times [@solymosi2020]. Others also identify that the number of participants in crowdsourcing projects tends to decrease over time (i.e., participation decrease), and some platforms have difficulties to engage participant and can only record small samples [e.g., @blom2010]. We will briefly review some of these strengths and weaknesses of crowdsourced data and illustrate some of them with data about perceptions of safety in Atlanta.






@solymosi2020 STRENGTHS

Capture the spatial-temporal specific nature of attitudes and emotions towards crime.	23/27
Record data on individual variables and specific types of fear/disorder.	12/27
Record data on architectural features.	20/27
Reduced cost of data collection.	11/27


WEAKNESSES

Self-selection bias:
males tend to be more represented than females, and young citizens are overrepresented compared to older groups @chataway2017
check @salesses2013

Participation inequality:
FixMyStreet data, one fourth of all reports had been produced by one percent of users, while 73% of people in the sample contributed only once (@solymosi2017).

Under-representation of certain areas

Participation decrease, sample attrition over time @solymosi2020 @blom2010

Repeatedly asking about fear might increase/cause fear

Lack of temporal variability in some web-based measures 

Validity of measures

# 3. Crowdsourcing perceptions of safety: Step-by-step example in R

In order to illustrate the use of crowdsourced data in criminological research, we present below an exemplar study using data recorded by the Place Pulse 2.0 platform [@salesses2013]. This section will introduce the Place Pulse project and provide `R` codes to download, explore and clean this source of crowdsourced data. Then, we will analyse the spatial distribution of crowdsourced perceptions of space and safety in Atlanta, Georgia, and illustrate with examples some known issues of crowdsourced data (i.e., participantion inequality, participation decrease and measure validity).

## 3.1 The Place Pulse project

Place Pulse 2.0 was an online crowdsourcing platform designed to record data about citizens' perceptions of safety, beauty, wealth, liveability, boredom and depression. Two images obtained were shown to participants, who then were asked ‘Which place looks safer?’ (see Figure 1). The platform could also be used to report which of the two images looked wealthier, more beautiful, more boring, livelier or more depressing, but we will focus on the 'safer' answers in this chapter. Images were selected randomly from Google Street View across 56 cities from 28 countries, and these captions were originally taken between 2007 and 2012. The platform recorded all responses in a public dataset, but responders did not provide any further information about themselves, which means that we do not know their social and demographic characteristics. Place Pulse used to be hosted in an open website (http://pulse.media.mit.edu/) and anyone could use it, but the platform was closed in 2019. We have been granted access to all the data recorded between the 28th May 2013 and the 22nd August 2019 to write this chapter, which has been uploaded onto an open repository with consent of the data producers [@salesses2013].

![Figure 1: Place Pulse website](figures/Place_Pulse.jpg)

## 3.2 Download and explore Place Pulse data

We have saved all Place Pulse data in a data repository on FigShare. You can download this directly into `R` by using the `read.csv()` function. It is a large file so it may take some minutes to read in.

```{r readpp}

pp_data <- read.csv('https://ndownloader.figshare.com/files/21739137') 

```

This data set includes 17 variables, but we will only use some of them. A unique identification code was given to each participant (*'voter_uniqueid'*) and image (*'place_id_left'* for images in the left side of the pairwise comparison and *'place_id_right'* for images in the right part). The columns *'place_name_left'* and *'place_name_right'* specify the city of each photograph. The column *'choice'* shows if the user perceived the image in the left or right to be 'safer' (participants could also answer 'equal'), and the column *'study_question'* allows studying perceptions about different variables (e.g., safety, wealth, beauty). The columns *'day'* and *'time'* specify the moment when each vote took place, and the columns *'long_right'*, *'lat_right'*, *'long_left'* and *'lat_left'* show the longitude and latitude of both photographs.

We can begin by examining which cities were more frequenty assessed within the Place Pulse platform. This can be checked for images in the left side of the pairwise comparison first, and then for images in the right. We can use the `group_by()` and `summarize()` functions from `dplyr` package [@wickham2020] to check this:

```{r top5placeleft}

pp_data %>%
  group_by(place_name_left) %>% # categories based on cities on the left
  summarize(Count = n()) %>% # count number of units in each category
  top_n(3) # print 3 most frequent categories

```

Atlanta was the city with a largest number of votes amongst those images that appeared in the left part of the comparison, but we can also check this for those images shown in the right side:

```{r top5placeright}

pp_data %>%
  group_by(place_name_right) %>% # categories based on cities on the right
  summarize(Count = n()) %>% # count number of units in each category
  top_n(3) # print 3 most frequent categories


```

Atlanta was indeed the city with the largest number of votes. We can also check which variables (e.g., safety, beauty, wealth) were more frequently assessed by participants:

```{r topstudyquestions}

pp_data %>%
  group_by(study_question) %>% # categories based on study questions
  summarize(Count = n()) # count number of units in each category

```

We see that safety was the most commonly assessed variable, with 509,961 votes in total. In this chapter we will examine reports of safety in the city of Atlanta. Before analysing the data, however, we can also examine if participants were more inclined to vote for images in the left or right part of the platform. In other words, we analyse if responses were biased by the position in which images were shown on the website.

```{r topchoice}

pp_data %>%
  group_by(choice) %>% # categories based on vote (right, left or equal)
  summarize(Count = n()) %>% # count number of units in each category
  top_n(3) # print 3 most frequent categories

```

The frequency of votes for left and right options is very similar, and thus we can conclude that the position of the image on the web does not appear to have an affect on participants' votes.

## 3.3 Cleaning Place Pulse data

When it comes to crowdsourced data, you will have to be an expert data wrangler to make sure you can get the data to behave like you want it to - in other words, to make the data available in a format that allows you to answer your research questions. For example, in this case, we want to map the perceived safety of areas in Atlanta. To do this, first we have to select the area of Atlanta and the votes about safety.

Atlanta is the capital city of the State of Georgia, in the US. In 2018, its estimated papulation was close to 500,000 residents, and thus it is the 37th most populated city in the United States. There are two main reasons why we are conducting this exemplar study in Atlanta: first, as shown above, it was the city with the largest number of votes in the Place Pulse platform; and second, there is available open data about the social, demographic and crime characteristics of Atlanta neighborhoods, which can be easily accessed to explain the patterns observed in Place Pulse data. Moreover, various papers have analysed the predictors of crime and fear of crime in this city, which can be used to interpret our results [see @mcnulty2000; @tester2011]

We can use the function `filter()` from `dplyr` to create a new dataframe that includes those pairwise comparisons in which either the image of the right or the image of the left, or both, are from Atlanta.

```{r getatlandapp}

# select cases in which the image of the right or the image of the left was from Atlanta
pp_atl <- pp_data %>%
  filter(place_name_right == "Atlanta" | place_name_left == "Atlanta")

```

We will also focus on the ratings of areas as safer, as we are interested in people's perceptions of place and safety: 

```{r getsafetyq}

pp_atl_s <- pp_atl %>%
  filter(study_question == "safer") # select votes of 'safer'

```

You can see now that we have a dataframe of `r nrow(pp_atl_s)` votes about the safety of places in Atlanta.

We are interested in analysing the proportion of 'safer' votes in each neighbourhood of Atlanta. In order to assign each photograph to their neighbourhood, we need to create two new columns that specify the longitude and latitude of the image being assessed. We will also create a new column that details whether each participant voted that the image of Atlanta was 'safer' or 'not safer' (i.e., less safe or equal) than the other picture. Some pairwise comparisons, however, assessed two different images from Atlanta, which means that we will need to duplicate these votes to account for both the image on the right and left of the pariwise comparison. First, we want to know the number of comparisons in which both images are from Atlanta. We can use the function `filter()` from `dplyr`, which we have already used above.

```{r counttwoatlanta}

# create dataset of votes in which both images are from Atlanta
pp_atl_s_dup  <- pp_atl_s %>%
    filter(place_name_right == "Atlanta" & place_name_left == "Atlanta") 

# print the count of votes as a result
pp_atl_s_dup %>%
    summarize(count = n()) 

```

In total, 678 pairwise comparisons are based on two images from Atlanta, whereas 36,536 compare one image from Atlanta with a picture from any other city. We will duplicate those comparisons in which both images were taken in Atlanta and attach them to two new datasets (one to assess the images on the right, and the other to report the images on the left). For now, we delete duplicated cases from the main dataframe by using the `anti_join()` function from `dplyr`, which searches those duplicated units that exist in the newly created dataset `pp_atl_dup` and deletes them from the main dataset of votes. We will merge all units together once all the data has been cleaned.

```{r duplicatedatatwoatlanta}

# duplicate the new dataset
pp_atl_s_dup2 <- pp_atl_s_dup 

# delete duplicated votes from main dataset
pp_atl_s <- pp_atl_s %>%
  anti_join(x = pp_atl_s, y = pp_atl_s_dup, by = "X")

```

Now, the main dataset includes only those pairwise comparison in which only one image is from Atlanta. We create two new columns that specify the coordinates of the photograph from Atlanta. We use the `mutate()` function from `dplyr` to create the new columns and the `if_else()` function to copy the coordinates of the image of the left or right depending on whether the left photoraph was from Atlanta or not.

DELETE: First, we allocate the coordinates to those votes in which the image of the left is from Atlanta:

```{r coordsleftpic}

# copy longitude and latitude from left image if left image is from Atlanta, 
# otherwise copy from the right image
pp_atl_s <- pp_atl_s %>%
    mutate(long_Atl = if_else(place_name_left == "Atlanta", long_left, long_right),
           lat_Atl  = if_else(place_name_left == "Atlanta", lat_left , lat_right))

```

Remember that we had previously created two new datasets with those votes in which both images are from Atlanta. The first dataset (`pp_atl_s_dup`) will be used to assess the images in the left, while the second dataset (`pp_atl_s_dup2`) refers to the images in the right. We can then allocate the coordinates of the left image to first dataset of votes in which both images are from Atlanta:

```{r coordslefttwoatlanta}

# copy coordinates from left image to new columns
pp_atl_s_dup <- pp_atl_s_dup %>%
  mutate(long_Atl = long_left,
         lat_Atl  = lat_left)

```

And then we allocate the coordinates of the right image to the second dataset of pairwise comparisons between Atlanta pictures:

```{r coordsrighttwoatlanta}

# copy coordinates from right image to new columns
pp_atl_s_dup2 <- pp_atl_s_dup2 %>%
  mutate(long_Atl = long_right,
         lat_Atl  = lat_right)

```

Before merging all the data into a single dataset, we will also create a new column that distinguishes those images of Atlanta that were assessed as 'safer' from those reported as 'less safe' or 'equal'. We do this first in the main dataset (which only includes pairwise comparisons with one picture from Atlanta), by checking if the choice of each vote (i.e., 'left', 'right', or 'equal') corresponds to the position of the image from Atlanta. We assign a 1 if the user choose the image of Atlanta as 'safer', whereas a 0 is assigned when the image of a different city was chosen to be 'safer' and when users voted 'equal'. We can also use the `mutate()` and `if_else()` functions from `dplyr` here.

```{r assign1or0}

# if left image is from Atlanta and user voted for left image, assing 1, otherwise 0
# if right image is from Atlanta and user voted for right image, assign 1, otherwise 0
pp_atl_s <- pp_atl_s %>%
  mutate(win = if_else((place_name_left  == "Atlanta" & choice == "left") |
                       (place_name_right == "Atlanta" & choice == "right"), 1, 0))

```

Similarly, in the `pp_atl_s_dup` dataset, we assign a 1 to those cases in which participants voted for the left image as 'safer' and a 0 otherwise, given that this dataset had been previously created to assess left images in cases when both images were from Atlanta. And we do the same with the second dataset (`pp_atl_s_dup2`) that compares two images from Atlanta, which in this case refers to the image in the right.

```{r assign1or0twoatlanta}

# if participant voted for left image, assign 1, otherwise 0
pp_atl_s_dup <- pp_atl_s_dup %>%
  mutate(win = if_else(choice == "left", 1, 0))

# if participant voted for righ image, assign 1, otherwise 0
pp_atl_s_dup2 <- pp_atl_s_dup %>%
  mutate(win = if_else(choice == "right", 1, 0))

```

Now that our dataset has been cleaned and is ready to be analysed, we can merge all the data together wit the `rbind()` function.

```{r merge}

pp_atl_s <- rbind(pp_atl_s, pp_atl_s_dup, pp_atl_s_dup2) 

```

We have a dataframe of `r nrow(pp_atl_s)` votes about the safety in Atlanta that is ready to be analysed.

## 3.4 Map Place Pulse data

It is possible to use mapping techniques learned in other chapters (LINK WITH MAPPING CHAPTER) to map the crowdsourced data [see also @solymosi2015]. We will be using the `sf` and `ggplot2` libraries in order to create a map of perceived safety of built environment across the areas of Atlanta.

First, acquire a shapefile for Atlanta. Let's use the census tracts shapefile from Harvard University. You can go on their website to find out more about this boundary data: [https://worldmap.harvard.edu/data/geonode:Atlanta_Census_Tracts_SHL](https://worldmap.harvard.edu/data/geonode:Atlanta_Census_Tracts_SHL). We can download the shapefile directly using their Application Programme Interfact (or API) - this is something discussed in greater detail on the chapter on Open Data (CHAPTER REF LANGTON AND SOLYMOSI, 2020). For now, you can just use the code below, with the `st_read()` function in the `sf` package: 

```{r loadshapefile}

atl <- st_read("http://worldmap.harvard.edu/download/wfs/1824/json?outputFormat=json&service=WFS&request=GetFeature&format_options=charset%3AUTF-8&typename=geonode%3AAtlanta_Census_Tracts_SHL&version=1.0.0")

```

We can see what this file looks like by using the `plot()` function to plot the geometry of the 'atl' object we created, called with the `st_geometry()` function: 

```{r plotatlgeom}

plot(st_geometry(atl))

```

Now, to be able to plot the safety votes on this map, we first need to make our votes a spatial object, by specfying that the "long_Atl" and "lat_Atl" columns contain our longitude and latitude information. We use the `st_as_sf()` function for this: 

```{r geocodepp}

points_atl_s <- st_as_sf(pp_atl_s, coords = c("lat_Atl", "long_Atl")) #geocode 'safe' votes in Atlanta

```

In order to plot both these spatial layers (i.e., votes recorded from Place Pulse and Atlanta census tracts) on the same map, their coordinate reference systems (CRS) need to match. We can check these with the `st_crs()` function: 

```{r checkcrs}

st_crs(points_atl_s) == st_crs(atl) #check if coordinate reference system is the same of both layers

```

We function tells us that it is 'false' that both CRS are not equal, but we can change this with the following line of code:

```{r changecrs}

st_crs(points_atl_s) <- st_crs(atl)

```

Now, if we check, they should have the same CRS: 

```{r checkcrs2}

st_crs(points_atl_s) == st_crs(atl) #check if coordinate reference system is the same of both layers

```

Thus, we can now map our data. See (LINK WITH MAPPING CHAPTER) for more information about crime mapping.

```{r plotpoints}

map <- ggplot(data = atl) + geom_sf() + theme_void() +
       coord_sf(xlim = c(-84.7, -84), ylim = c(33.6, 34), 
                expand = FALSE) #create map
  
map + geom_point(data = pp_atl_s, aes(x = lat_Atl, y = long_Atl),
                 size = .1) #plot map with points

```

This is a very busy map. Maybe instead we want to get some sort of average score for each census tract. We then calculate the proportion of 'safer' responses in each area [see @builgil2020]. Note that @salesses2013 suggest computing a Q-score per image corrected by the "win" and "loss" ratio of all photographs with which it is compared, but for the purpose of this chapter we will compute a simple proportion that will allow us to directly analyse the geographical distribution of perceived safety. 

```{r calcwinscore}

points_atl_s_nhood <- st_intersection(atl, points_atl_s) %>% 
                      group_by(TRACT) %>% 
                      summarise(winscore = mean(win, na.rm = TRUE), 
                                num_votes = n())

```

And we can add the average score of 'safer' reponses per area to the original shapefile of census tracts. We will also delete those census tracts in which we do not have any vote of perceived safety.
 
```{r joinwin}

st_geometry(points_atl_s_nhood) <- NULL

# merge census tracts and Place Pulse votes based on TRACT column
atl_pp_wins <- left_join(atl, points_atl_s_nhood, by = c("TRACT" = "TRACT"))

# delete census tracts with 0 votes (NAs)
atl_pp_wins <- atl_pp_wins[!is.na(atl_pp_wins$winscore), ]

```

Finally, we can plot the propotion of 'safer' votes in each census tract.

```{r mapwins}

ggplot(data = atl_pp_wins) + 
  geom_sf(aes(fill = winscore)) +
  coord_sf(xlim = c(-84.7, -84), ylim = c(33.5, 34), expand = FALSE) +
  theme_void() 

```

There are many more things one can do with these data. For example, we could look at the descriptive statistics and boxplot of the proportion of 'safer' votes in each area: 

```{r}

summary(atl_pp_wins$winscore) # descriptive statistics of proportion of 'safer' votes per tract

p <- ggplot(atl_pp_wins, aes(y = winscore))

p + geom_boxplot() + ggtitle("Boxplot of percentage of 'safer' votes per area") # boxplot

```

You can do much more, but here we will focus on the specific issues to explore due to the crowdsourced nature of these data.

## 3.5 Exploring the known issues of crowdsourced data within Place Pulse

In section 2, we mentioned a few issues that are usually present in crowdsourced data, and which are important to keep in mind when ussing these data in criminological research. Here we explore whether some of these issues are present in data recorded from Place Pulse, and what that might mean for any conclusions we draw from our analyses. We shall keep in mind that the Place Pulse project did not record information about participants demographic characteristics, and thus we cannot direclty examine the self-selection biases that may affect this dataset [@builgil2020]. Nevertheless, the sample's self-selection biases should be checked when possible. For instance, the first edition of Place Pulse, which was designed to register some demographic variables from participants, identified that 76.0% of those who reported their gender were males, and only 21.1% were females, and the median self-reported age was 28 years [@salesses2013]. Here we examine data from Place Pulse 2.0, which does not record social and demographic variables from participants, but we will examine whether our sample size is affected by other issues such as participation inequality, under-representation of certain areas and participation decrease. We will also study the validity of these crowdsourced data as a measure of perceived safety.

### 3.5.1 Participation inequality (supercontributors)

Crowdsourced data is usually affected by a few number of supercontributors that produce most votes. In order to check if our dataset is affected by this, we first need to create a new dataframe showing the number of votes that each study participant had made. To do this, we will use code from the `dplyr` library:

```{r create voter table}

voter <- pp_data %>% 
  group_by(voter_uniqueid) %>% 
  summarise(num_votes = n())

```

If you want, you can have a look at this new dataframe using the `View()` function. If you do this, you might see, we have some very active participants. The top voter, for instance, has made `r voter %>% arrange(-num_votes) %>% head(1) %>% pull(num_votes)` votes on places. That is some very prolific participation! On the other hand, you can also see that `r nrow(voter %>% filter(num_votes == 1))` of the participants made only one vote. We are definitely seeing signs of participation inequality in these data. 

In fact, we can examine how much of the votes are produced by these "supercontributors". For example, we can assess the proportion of votes made by the top 1% of voters. We can do this using the `subset()` and `quantile()` functions:

```{r top1perc}

# subset the top 1% of most prolific participants
top_1percent <- subset(voter, num_votes > quantile(num_votes, prob = 1 - 1/100)) 

```

We can see that this new dataframe contains 954 people, who are our top 1% contributors to the Place Plus dataset. We will now examine how much of the total number of votes are generated by the top 1% of users:

```{r top1perccontrib}

sum(top_1percent$num_votes) / sum(voter$num_votes) * 100

```

That is a lot: `r round(sum(top_1percent$num_votes) / sum(voter$num_votes) * 100, 2)`% of the votes are made by the top 1% of contributors.

#### Activity 1

Can you tell me what proportion of the votes were made by the top 10% of participants? What about the top 25%? 

```{r activity1, echo = FALSE, eval=FALSE}

top_10percent <- subset(voter, num_votes > quantile(num_votes, prob = 1 - 10/100)) #subset top 10% participants

sum(top_10percent$num_votes) / sum(voter$num_votes) * 100 #Proportion of votes by top 10% participants

top_25percent <- subset(voter, num_votes > quantile(num_votes, prob = 1 - 25/100)) #subset top 25% participants

sum(top_25percent$num_votes) / sum(voter$num_votes) * 100 #Proportion of votes by top 25% participants

```

### 3.5.2 Quantifying participation inequality

One way to quantify the extent to which participation inequality exists in our data is by using a Gini index, and visualising it using a Lorenz curve. The Gini index (or Gini ratio) is a measure of statistical dispersion intended to measure inequality [@gastwirth1972]. Although it tends to be used to examine income inequality, it has also been frequently used to assess participation inequality in crowdsourcing platforms [see @solymosi2017; @solymosi2018]. Similarly, the Lorenz curve is a visual representation of inequality. For this you will need the library `ineq` [@zeileis2015] so if you do not already have this you must install with the command: 

```{r, eval = FALSE}

install.packages("ineq") 

```

Then you can load this library and calculate the index using the `Gini()` function: 

```{r gini}

Gini(voter$num_votes)

```

Remember that a score of 0 is perfect equality (everyone makes equal number of votes), while 1 is perfect inequality (only one person making all the reports, and no one else making any). Our answer of `r round(Gini(voter$num_votes), 2)` shows some serious inequality. To put this into context, in 2017, according to the OECD, income inequality in the United States of America showed a Gini coefficient of 0.39. To visualize this we can use a Lorenz curve using the `plot()` and `Lc()` functions: 

```{r lorenz}

plot(Lc(voter$num_votes),
     xlab = "Cumulative share of participants from lowest to higher number of votes",
     ylab = "Cumulative share of votes", col = "darkred", lwd = 2) 

```

The Lorenz curve (red line) above shows how the top few percent of reporters contribute the majority of the reports. If we had perfect equality, we would expect to see the red line align perfectly with the black line with the slope of 1. With this information we can now quantify how severe the participation inequality is in our data, and compare with other crowdsourced data for context and understanding. 

### 3.5.3 Under-representation of certain areas

It is also important to consider variation in the sample size of number of votes in each census tract. We can analyse it certain areas are under-represented in our dataset by using the `summary()` function.

```{r samplesize}

summary(atl_pp_wins$num_votes)

```

Whereas the average sample size per area is quite large, 

CONTINUE HERE!!



Talk a little about the issues with this and then discuss this:
Note: Buil-Gil et al. (2020) @builgil2020 propose a new method to compute estimates for areas with small sample sizes



### 3.5.4 Study participation descrease in Place Pulse

!!!This should also be broken up and motivated/exaplained!!!

```{r datestuff}

by_day <- pp_data %>% 
          mutate(day = ymd(day)) %>% 
          group_by(day) %>% 
          summarise(num_votes = n()) %>% 
          complete(day = seq.Date(min(day), max(day), by = "day")) %>% 
          mutate(num_votes = replace_na(num_votes, 0))


ggplot(by_day, aes(x = day, y = num_votes)) + 
       geom_line() + 
       geom_smooth(lwd = 1.5, col = "red") + 
       theme_bw() + 
       xlab("Days since website launch") + 
       ylab("Number of votes") 

```

Note: large peak beginning on July 24th 2013: publication of @salesses2013 on July 24th and press release via MIT News (http://news.mit.edu/2013/quantifying-urban-perceptions-0724)
Note: large peak beginning on October 15th 2014: publication of @Harvey2014 MSc thesis


### 3.4.5 Measure validity

Validity of an assessment is the degree to which it measures what it is supposed to measure. 

# Conclusions

Open topics in crowdsourced data

Further applications to crime and place research

# Authors bios

David Buil-Gil is a Research Fellow at the Department of Criminology of the University of Manchester, UK, and a member of the Cathie Marsh Institute for Social Research at this same university. His research interests cover small area estimation applications in criminology, environmental criminology, crime mapping, emotions about crime, crime reporting, new methods for data collection and open data.

Reka Solymosi is a Lecturer in Quantiative Methods at the Department of Criminology of the University of Manchetser, UK, with interests in data analysis and visualization, crowdsourcing, rstats, fear of crime, transport, and collecting data about everyday life. As a former crime analyst, she is interested in practical applications to research and solving everyday problems with data.

# References