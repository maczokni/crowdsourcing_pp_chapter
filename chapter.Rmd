---
title: "Crowdsourcing public perceptions of space and safety"
author: |
  | David Buil-Gil and Reka Solymosi
  | Department of Criminology, University of Manchester
date: "31/03/2020"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
library(sf)
library(ineq)
library(lubridate)
library(tidyr)
library(dplyr)
```

# 1. Introduction/background: 

What is crowdsourcing?

What types of data are commonly crowdsourced?

# 2. Strengths and weaknesses of crowdsourced data

What are some strengths and weaknesses of crowdsourced data?

# 3. Crowdsourcing perceptions of safety: Step-by-step example in R

In order to illustrate the use of crowdsourced data in criminological research, we present below an exemplar study using data recorded by the Place Pulse 2.0 platform. This section will introduce the Place Pulse project and provide codes to download, explore and clean this source of crowdsourced data. Then, we will analyse the crowdsourced perceptions of space and safety in Atlanta, Georgia, as well as some known issues of crowdsourced data (i.e., participantion inequality and participation decrease).

## 3.1 The Place Pulse project

Place Pulse 2.0 was a crowdsourced platform designed to record data about citizens' perceptions of safety, beauty, wealth, liveability, boredom and depression. Two images obtained from Google Street View are shown to participants, who are then asked ‘Which place looks safer / wealthier / more beautiful / more boring / livelier / more depressing?’ (see Figure 1). Images were selected randomly across 56 cities from 28 countries, and these captions were originally taken between 2007 and 2012. Responders do not provide any further information about themselves, besides from the vote about which image looks safer, which means that we do not know the social and demographic characteristics of participants. Place Pulse used to be hosted in an open website (http://pulse.media.mit.edu/) and anyone could use it. Although the platform was closed in summer 2019, we have been granted access to all the data recorded between the XX of XXXX of XXXXX and the XX of XXXX of XXXXXX, which has been uploaded onto an open repository and will be used in this chapter.

![Figure 1: Place Pulse website](figures/Place_Pulse.jpg)

## 3.2 Download and explore Place Pulse data

We have saved some Place Pulse data in a data repository on FigShare. You can download this directly into R by using the `read.csv()` function. It is a large file so it may take some time to read in, be patient!

```{r readpp, eval=FALSE}
pp_data <- read.csv('https://ndownloader.figshare.com/files/21739137') 
```

```{r readppreal, echo=FALSE}
pp_data <- read.csv('datasets/data.csv') 
```

This data set includes 17 variables, but we will only use some of them. A unique identification code has been given to each participant (i.e., 'voter_uniqueid') and image, which can in the left (i.e., 'place_id_left') or right (i.e., 'place_id_right') part of each pairwise comparison. The columns 'place_name_left' and 'place_name_right' locate each image in its city. The column 'choice' shows if the user voted the image in the left, right, or equal, and the column 'study_question' allows us to study perceptions about different variables. 'day' and 'time' detail the moment when each vote toke place, and the columns 'long_right', 'lat_right', 'long_left' and 'lat_left' show the longitude and latitude of both images.

For instance, we can see which cities have a largest number of votes amongst images in the left part of the pairwise comparison. To do this we can use the `top_n()` function from `dplyr` package:

CHANGE THIS TO TIDYVERSE -> group_by %% summarise


```{r}
top_n(as.data.frame(table(pp_data$place_name_left)), 5)

```

Atlanta was the city with a largest number of votes. We can check if that was also the case among pictures shown in the right part of the comparison:

```{r}
top_n(as.data.frame(table(pp_data$place_name_right)), 5)

```

Atlanta was indeed the city with the largest number of votes. We can also check which variables were more frequently assessed by participants:


```{r}

table(pp_data$study_question)

```

Safety was the most commonly assessed variable, with 509,961 votes in total. Before analysing the data, we can also examine if participants were more inclined to vote for images in the left or right part of the platform.


```{r}
top_n(as.data.frame(table(pp_data$choice)), 3)

```

The frequency of votes for left and right options is very similar, which shows that the position of the image in the comparison does not have an affect on participants' votes.

## 3.3 Cleaning Place Pulse data

When it comes to crowdsourced data, you will have to be an expert data wrangler to make sure you can get the data to behave like you want it to - in other words to make the data available in a format that allows you to answer your research questions. For example, in this case, we want to map the perceives safety of areas in Atlanta. To do this, first we have to select the area of Atlanta, and the votes about safety: 

Let's focus on the city of Atlanta. SOME CONTEXT. 


```{r getatlandapp}

pp_atl <- pp_data[which(pp_data$place_name_right == "Atlanta" | pp_data$place_name_left == "Atlanta"), ]


```

Let's also focus on the ratings of areas as safer, as we are interested in people's perceptions of the environment: 

```{r getsafetyq}

pp_atl_s <- pp_atl[ which(pp_atl$study_question == "safer"), ]

```

You can see now we have a dataframe of `r nrow(pp_atl_s)` votes about the safety of places in Atlanta.

We are interested in analysing the proportion of 'safer' votes in each neighbourhood of Atlanta. We will create two new variables to specify the longitude and latitude of the image of Atlanta being assessed and one new variables that details whether the user voted 'safer' or other. Some pairwise comparisons, nevetheless, assessed two images from Atlanta, which means that we will need to duplicate these votes to account for both the 'safer' and the 'less safe' picture. First, we want to know the number of comparisons in which both images are from Atlanta.

```{r}

table(pp_atl_s$place_name_right == "Atlanta" & pp_atl_s$place_name_left == "Atlanta") #count votes in which both images are from Atlanta

```

In total, 678 pairwise-comparisons included in our dataset are based on two images from the city of Atlanta, whereas 36,536 compare one image from Atlanta with a picture from another city. We will duplicate those comparisons in which both images were taken in Atlanta and attach them to two new datasets. For now, we also delete these cases from the main dataset, but we will merge them again once all the data has been cleaned.

```{r}
pp_atl_s <- pp_atl_s[order(pp_atl_s$X), ] #order file by vote number

pp_atl_s_dup <- pp_atl_s[which(pp_atl_s$place_name_right == "Atlanta" & pp_atl_s$place_name_left == "Atlanta"), ] #new dataset: both images are from Atlanta
pp_atl_s_dup2 <- pp_atl_s_dup #duplicate new dataset

pp_atl_s <- pp_atl_s[!(pp_atl_s$X %in% pp_atl_s_dup$X),] #delete cases in which both votes are from Atlanta from main dataset

```

In the main dataset, that includes all votes with one image from Atlanta, we create new variables to detail the coordinates of the picture from Atlanta. First, we allocate the coordinates to those votes in which the left image is from Atlanta:

```{r}
pp_atl_s$long_Atl[pp_atl_s$place_name_left == "Atlanta"] <- pp_atl_s$long_left[pp_atl_s$place_name_left == "Atlanta"]
pp_atl_s$lat_Atl[pp_atl_s$place_name_left == "Atlanta"] <- pp_atl_s$lat_left[pp_atl_s$place_name_left == "Atlanta"]
```

Then, we allocate the coordinates to those votes in which the right image is from Atlanta:

```{r}
pp_atl_s$long_Atl[pp_atl_s$place_name_right == "Atlanta"] <- pp_atl_s$long_right[pp_atl_s$place_name_right == "Atlanta"] 
pp_atl_s$lat_Atl[pp_atl_s$place_name_right == "Atlanta"] <- pp_atl_s$lat_right[pp_atl_s$place_name_right == "Atlanta"]
```

Given that we have create two new datasets which those votes in which both images are from Atlanta, we will use the first one (`pp_atl_s_dup`) to assess the image in the left, and the second dataset (`pp_atl_s_dup2`) to examine the images in the right. We start by allocating the coordinates of the left image to first dataset of votes in which both images are from Atlanta:

```{r}
pp_atl_s_dup$long_Atl <- pp_atl_s_dup$long_left
pp_atl_s_dup$lat_Atl <- pp_atl_s_dup$lat_left
```

And the allocate the coordinates of the right image to the second dataset of pairwise comparisons between Atlanta pictures:

```{r}
pp_atl_s_dup2$long_Atl <- pp_atl_s_dup2$long_right
pp_atl_s_dup2$lat_Atl <- pp_atl_s_dup2$lat_right
```



#code 'safer' votes as 1 and 'less safe' and 'equal' as 0

```{r}
pp_atl_s$win[pp_atl_s$place_name_left == "Atlanta" & pp_atl_s$choice == "left"] <- 1
pp_atl_s$win[pp_atl_s$place_name_left == "Atlanta" & pp_atl_s$choice == "right"] <- 0
pp_atl_s$win[pp_atl_s$place_name_left == "Atlanta" & pp_atl_s$choice == "equal"] <- 0

pp_atl_s$win[pp_atl_s$place_name_right == "Atlanta" & pp_atl_s$choice == "right"] <- 1
pp_atl_s$win[pp_atl_s$place_name_right == "Atlanta" & pp_atl_s$choice == "left"] <- 0
pp_atl_s$win[pp_atl_s$place_name_right == "Atlanta" & pp_atl_s$choice == "equal"] <- 0

pp_atl_s_dup$win[pp_atl_s_dup$choice == "left"] <- 1
pp_atl_s_dup$win[pp_atl_s_dup$choice == "right"] <- 0
pp_atl_s_dup$win[pp_atl_s_dup$choice == "equal"] <- 0

pp_atl_s_dup2$win[pp_atl_s_dup$choice == "right"] <- 1
pp_atl_s_dup2$win[pp_atl_s_dup$choice == "left"] <- 0
pp_atl_s_dup2$win[pp_atl_s_dup$choice == "equal"] <- 0
```

#merge duplicated cases where both images are from Atlanta

```{r}
pp_atl_s <- rbind(pp_atl_s, pp_atl_s_dup, pp_atl_s_dup2) 
```


table(pp_atl_s$win) #count frequency of 'safer' votes in Atlanta against 'equal' and 'less safe' votes
prop.table(table(pp_atl_s$win))*100 #count % of 'safer' votes in Atlanta against 'equal' and 'less safe' votes


```

## 3.4 Map Place Pulse data

It is possible to use mapping techniques learned in other chapters (LINK WITH MAPPING CHAPTER PEOPLE) to map the crowdsourced data. 

 Let's plot this, to create a map of perceived safety of built environment across the city of Atlanta. For this, we will be using the `sf` and `ggplot2` libraries. 

First, acquire a shapefile for Atlanta. Let's use the neighbourhoods shapefile from the department of city planning. You can go on their website to find out more about this boundary data: [https://dcp-coaplangis.opendata.arcgis.com/datasets/neighborhoods](https://dcp-coaplangis.opendata.arcgis.com/datasets/neighborhoods). We can download the shapefile directly using their Application Programme Interfact (or API) - this is something discussed in greater detail on the chapter on Open Data (CHAPTER REF). For now, you can just use the code below, with the `st_read()` function in the `sf` package: 

```{r}

atl <- st_read("https://opendata.arcgis.com/datasets/297d3d69d8ab4c6ba5f9264ad5e75c0a_3.geojson")

```

We can see what this looks like by using the `plot()` function to plot the geometry of the atl object we created, called with the `st_geometry()` function: 

```{r plotatlgeom}

plot(st_geometry(atl))


```


Now to be able to plot the safety votes on this map, we first need to make our votes a spatial object, by specfying that the "long_Atl" and "lat_Atl" contain our longitude and latitude information. We use the `st_as_sf()` function for this: 


```{r geocodepp}

points_atl_s <- st_as_sf(pp_atl_s, coords = c("lat_Atl", "long_Atl")) #geocode 'safe' votes in Atlanta

```


Now to be able to plot both these spatial layers on the same map, their coordinate reference systems need to match. We can check these with the `st_crs()` function: 

```{r checkcrs}
st_crs(points_atl_s) == st_crs(atl) #check if coordinate reference system is the same of both layers
```

We see they do not! We can fix this by setting the CRS of our point data to that of the atl shapefile using the `st_crs()` function: 

```{r changecrs}
st_crs(points_atl_s) <- st_crs(atl)

```

Now if we check, they should have the same CRS: 

```{r checkcrs2}
st_crs(points_atl_s) == st_crs(atl) #check if coordinate reference system is the same of both layers
```

Indeed! Now we can map our data!

```{r plotpoints}

ggplot(data = atl) + 
  geom_sf() + 
  theme_void() + 
  geom_sf(data = points_atl_s) #visualise points on the map

```




This is a very busy map! Maybe instead we want to get some sort of average score for each neighbourhood. 

Get win score for each nhood

```{r calcwinscore}

points_atl_s_nhood <- st_intersection(atl, points_atl_s) %>% 
  group_by(NAME) %>% 
  summarise(winscore = mean(win, na.rm = TRUE), 
            num_votes = n())

```

 Join to shapefile
 
```{r joinwin}

st_geometry(points_atl_s_nhood) <- NULL

atl_pp_wins <- left_join(atl, points_atl_s_nhood, by = c("NAME" = "NAME"))

```


```{r mapwins}
ggplot(data = atl_pp_wins) + 
  geom_sf(aes(fill = winscore)) + 
  theme_void() 



```


About this: 
Note: Salesses et al. (2013) suggest computing a Q-score corrected by the "win" and "loss" ratio of imagines with which each vote is compared for the purpose of this chapter we will compute a simple proportion - should we include this for an activity? 


There are many more things you can do with these data. for example you could look at the descriptive statistics: 

```{r}

summary(atl_pp_wins$winscore) #descriptive statistics of proportion of 'safer' votes per tract


```


Important also to consider variation in the sample size of number of votes in each neighbourhood:

```{r samplesize}

summary(atl_pp_wins$num_votes)

```

Talk a little about the issues with this and then discuss this:
Note: Buil-Gil et al. (2020) propose a new method to compute estimates for areas with small sample sizes



You can do much more, but here we will focus on the specific issues to explore due to the crowdsourced nature of these data!

## 3.5 Exploring the known issues of crowdsourced data within Place Pulse

We mentioned a few issues that are usually present in crowdsourced data, and which are important to keep in mind. Here we explore whether they are present in Place Pulse, and what that might mean for any conclusions we draw from our analyses. 

First, create a new dataframe showing the number of votes that each study participant had made. To do this, we will use code from the `dplyr` library: 

```{r create voter table}
voter <- pp_data %>% 
  group_by(voter_uniqueid) %>% 
  summarise(num_votes = n())

```


If you want, you can have a look at this new dataframe using the `View()` function. If you do this, you might see, we have some very active participants! The top voter there has made `r voter %>% arrange(-num_votes) %>% head(1) %>% pull(num_votes)` votes on places! That is some very prolific participation! On the other hand, you can also see that `r nrow(voter %>% filter(num_votes == 1))` of the participants made only one vote! We are definitely seeing signs of participation inequality in these data. 

### 3.5.1 Participation inequality (supercontributors)

In fact, let's see, how much of the votes do the "supercontributors" account for? Let's say we want to consider the top 1% of voters. We can do this using the `subset()` and `quantile()` functions:

```{r top1perc}

top_1percent <- subset(voter, num_votes > quantile(num_votes, prob = 1 - 1/100)) 

```

We can see that this new dataframe contains 954 people, who are our top 1% contributors to the Place Plus data set. Let's see how much of the total number of votes they contribute:


```{r top1perccontrib}

sum(top_1percent$num_votes) / sum(voter$num_votes) * 100

```

That is a lot! `r round(sum(top_1percent$num_votes) / sum(voter$num_votes) * 100, 2)`% of the votes are made by the top 1% of contributors!

#### Activity 1

Can you tell me what proportion of the votes were made by the top 10% of participants? What about the top 25%? 

```{r activity1, echo = FALSE, eval=FALSE}


top_10percent <- subset(voter, num_votes > quantile(num_votes, prob = 1 - 10/100)) #subset top 10% participants

sum(top_10percent$num_votes) / sum(voter$num_votes) * 100 #Proportion of votes by top 10% participants

top_25percent <- subset(voter, num_votes > quantile(num_votes, prob = 1 - 25/100)) #subset top 25% participants

sum(top_25percent$num_votes) / sum(voter$num_votes) * 100 #Proportion of votes by top 25% participants

# what is this line?:
# N_votes <- as.data.frame(table(Voter$Freq)) #create dataframe of number of participants that voted X times

```

### 3.5.2 Quantifying participation inequality

One way to quantify the extent to which participation inequality exists in our data is by using a Gini index, and visualising using a Lorenz curve. 

For this you will need the library `ineq` so if you don't already have this you must install with the command: 

```{r, eval = FALSE}

install.packages("ineq") 

```

Then you can load this library and calculate the index using the `Gini()` function: 

```{r gini}

Gini(voter$num_votes)

```

Remember that a score of 0 is perfect equality (everyone makes equal number of votes), while 1 is perfect inequality (only one person making all the reports, and no one else making any) . Our answer of `r round(Gini(voter$num_votes), 2)` shows some serious inequality. To put this into context, in 2017, according to the OECD, income inequality in the United States of America showed a Gini coefficient of 0.39.  
To visualise this we can use a Lorenz curve using the `plot()` and `Lc()` functions: 

```{r lorenz}

plot(Lc(voter$num_votes), xlab = "Cumulative share of participants from lowest to higher number of votes",
     ylab = "Cumulative share of votes",col="darkred",lwd=2) 

```

The Lorenz curve (red line) above shows how the top few percent of reporters contribute the majority of the reports. If we had perfect equality, we would expect to see the red line align perfectly with the black line with the slope of 1. 

With this information we can now quantify how severe the participation inequality in our data, and compare with other crowdsourced data for context and understanding. 


### 3.5.3 Study participation descrease in Place Pulse

!!!This should also be broken up and motivated/exaplained!!!

```{r datestuff}

by_day <- pp_data %>% 
  mutate(day = ymd(day)) %>% 
  group_by(day) %>% 
  summarise(num_votes = n()) %>% 
  complete(day = seq.Date(min(day), max(day), by="day")) %>% 
  mutate(num_votes = replace_na(num_votes, 0))


ggplot(by_day, aes(x = day, y = num_votes)) + 
  geom_line() + 
  geom_smooth(lwd = 1.5, col = "red") + 
  theme_bw() + 
  xlab("Days since website launch") + 
  ylab("Number of votes") 

```


Note: large peak beginning on July 24th 2013: publication of @salesses2013 on July 24th and press release via MIT News (http://news.mit.edu/2013/quantifying-urban-perceptions-0724)
Note: large peak beginning on October 15th 2014: publication of @Harvey2014 MSc thesis


# Wrap-up/Where to next:

## Open topics in crowdsourced data

## Further applications to crime and place research
